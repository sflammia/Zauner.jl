export re_im_proj, precision_bump, precision_bump!

@doc """
    re_im_proj(ψ::Vector{Complex{BigFloat}})
    re_im_proj(z::Vector{BigFloat})

Stack the real and imaginary parts of the vector `ψ` and normalize so that
the first coordinate, assumed nonzero, is normalized to 1 and then dropped.

If called with type `Vector{BigFloat}` then it does the inverse transformation,
taking an even-length real vector to a complex one with unit first coordinate.

# Examples
A simple example:
```jldoctest
v = Complex{BigFloat}.([ 1; im; -1; -im])
re_im_proj(v)

# output

6-element Vector{BigFloat}:
  0.0
 -1.0
  0.0
  1.0
  0.0
 -1.0
```
"""
function re_im_proj(ψ::Vector{Complex{BigFloat}})
    ψ[1] ≈ zero(eltype(ψ)) && error("First entry must be nonzero.")
    vcat(reim(ψ[2:end] ./ ψ[1])...)
end


function re_im_proj(z::Vector{BigFloat})
    @assert iseven(length(z))
    [1; z[1:end÷2]] .+ im * [0; z[(1+end÷2):end]]
end


#=
    *Empirically*, the following list is sufficient to get a
    square and full-rank Jacobian. There is room to optimize this.
    *No check* is done to ensure that the Jacobian is full rank,
    nor is any effort spent on optimizing the condition number through
    a judicious choice of rows. However, after taking the symmetries of
    the function into account, and dropping the (p,q) == (0,0) equation,
    these are the lexigraphically first independent terms in the real
    and imaginary parts. It is thus plausible that they should give a
    full-rank Jacobian, at least for generic perturbations.
=#
_lex_first_inds(d) = [
    [q for q = 1:d÷2];        # real part, first row
    [d + q for q = 1:d÷2];        # real part, second row
    [2d + q for q = 2:d÷2];        # real part, third row
    [d^2 + d + q for q = 1:(d-1)÷2];    # imag part, second row
    [d^2 + 2d + q for q = 2:(1-(-1)^d)]  # imag part, one element in the third row for odd d
]


# Take the real and imaginary parts with projective normalization and
# return the overlap function for a ghost fiducial.
# NOTE: This function has an eight-fold symmetry as a function of (p,q)
# generated by the transformations:
#    (p,q) → (-p,-q)
#    (p,q) → ( q, p)
#    (p,q) → ( p,-q)*
# where the last one means apply the symmetry then complex conjugate the result.
function _ghost_olp_func(z, r, p, q)
    T = eltype(z)
    d = 1 + length(z) ÷ 2
    x0 = [one(T); z[1:d-1]] # real part of ψ
    y0 = [zero(T); z[d:end]]  # imag part of ψ
    xi = circshift(reverse(x0), 1)
    yi = circshift(reverse(y0), 1)
    xp = circshift(xi, -p)
    yp = circshift(yi, -p)
    xq = circshift(xi, -q)
    yq = circshift(yi, -q)
    xr = circshift(x0, -p - q)
    yr = circshift(y0, -p - q)

    # real and imaginary parts.
    if r == 0
        # real part
        sum((xq .* xr + yq .* yr) .* (x0 .* xp + y0 .* yp) +
            (xr .* yq - xq .* yr) .* (xp .* y0 - x0 .* yp)) -
        ((p == 0) + (q == 0)) / (d + one(T)) * sum(xi .* x0 + yi .* y0)^2
    elseif r == 1
        # imaginary part
        if (p == 0 || q == 0 || 2p == d || 2q == d)
            zero(T) # these values are manifestly real and don't contribute.
        else
            sum((xq .* yr - yq .* xr) .* (x0 .* xp + y0 .* yp) +
                (yr .* yq + xq .* xr) .* (xp .* y0 - x0 .* yp))
        end
    end
end


# both real and imaginary parts on a combined index
_ghost_olp_func(z, n::Integer) = _ghost_olp_func(z, radix(n, [2, 1 + (length(z) ÷ 2), 1 + (length(z) ÷ 2)])...)

# list over a vector
_ghost_olp_func(z, v::AbstractVector) = [_ghost_olp_func(z, n) for n in v]


function _ghost_olp_func(z)
    d = 1 + length(z) ÷ 2
    _ghost_olp_func(z, _lex_first_inds(d))
end


# now we do the same thing for SIC overlaps
function _sic_olp_func(z, r, p, q)
    T = eltype(z)
    d = 1 + length(z) ÷ 2
    x0 = [one(T); z[1:d-1]] # real part of ψ
    y0 = [zero(T); z[d:end]]  # imag part of ψ
    xp = circshift(x0, -p)
    yp = circshift(y0, -p)
    xq = circshift(x0, -q)
    yq = circshift(y0, -q)
    xr = circshift(x0, -p - q)
    yr = circshift(y0, -p - q)

    # real and imaginary parts.
    if r == 0
        # real part
        sum((xq .* xr + yq .* yr) .* (x0 .* xp + y0 .* yp) +
            (xr .* yq - xq .* yr) .* (xp .* y0 - x0 .* yp)) -
        ((p == 0) + (q == 0)) / (d + one(T)) * sum(x0 .* x0 + y0 .* y0)^2
    elseif r == 1
        # imaginary part
        if (p == 0 || q == 0 || 2p == d || 2q == d)
            zero(T) # these values are manifestly real and don't contribute.
        else
            sum((xq .* yr - yq .* xr) .* (x0 .* xp + y0 .* yp) +
                (yr .* yq + xq .* xr) .* (xp .* y0 - x0 .* yp))
        end
    end
end


# both real and imaginary parts on a combined index
_sic_olp_func(z, n::Integer) = _sic_olp_func(z, radix(n, [2, 1 + (length(z) ÷ 2), 1 + (length(z) ÷ 2)])...)

# list over a vector
_sic_olp_func(z, v::AbstractVector) = [_sic_olp_func(z, n) for n in v]


function _sic_olp_func(z)
    d = 1 + length(z) ÷ 2
    _sic_olp_func(z, _lex_first_inds(d))
end



@doc """
    precision_bump(ψ::Vector{Complex{BigFloat}}, prec::Integer [; base::Integer = 10, verbose::Bool = true])
    precision_bump(ψ::Vector{Complex{BigFloat}}, f::Function, prec::Integer [; base::Integer = 10, verbose::Bool = true])

Attempt to use Newton's method to improve the precision of `ψ` to at least `prec` digits in base `base`.
In the second version, the function `f` is used for root finding.
"""
function precision_bump(ψ::Vector{Complex{BigFloat}}, prec::Integer; base::Integer=10, verbose::Bool=true)
    z = re_im_proj(ψ)
    precision_bump!(z, prec; base, verbose)
    re_im_proj(z)
end



@doc raw"""
    precision_bump!(z::Vector{BigFloat}, prec::Integer [; base::Integer = 10, verbose::Bool = true])
    precision_bump!(z::Vector{BigFloat}, f::Function, prec::Integer [; base::Integer = 10, verbose::Bool = true])

Attempt to use Newton's method to improve the precision of `z` to at least `prec` digits in base `base`,
where `z` is the real projective representation of `ψ`.
In the second version, the function `f` is used for root finding.
"""
function precision_bump!(
    z::Vector{BigFloat},
    prec::Integer;
    f::Function=_ghost_olp_func,
    base::Integer=10,
    verbose::Bool=false
)
    basename = _base_name(base)

    # Save global precision
    old_bits = precision(BigFloat)
    min_digits = ceil(Int, 53 / log2(base))

    try
        # Estimate current accuracy
        resid = maximum(abs.(f(z)))
        digits = floor(Int, -log(base, resid))
        digits = max(digits, min_digits)  # floor at ~Float64 accuracy

        verbose && println("Increasing precision using Newton's method.")
        verbose && println("Tracking precision in $(basename).")
        verbose && println("-"^(27))
        verbose && println("Step   Accuracy   Precision")
        verbose && println("-"^(27))
        step = 0
        verbose && println("$(lpad(step, 4))    $(lpad(digits, 7))    $(lpad(precision(BigFloat; base = base), 8))")
        while digits < prec
            # Increase global precision (in bits)
            new_bits = ceil(Int, 2 * digits * log2(base))
            setprecision(BigFloat, new_bits)

            z .-= jacobian(f, z) \ f(z)

            # Recompute accuracy
            step += 1
            verbose && println("$(lpad(step, 4))    $(lpad(digits, 7))    $(lpad(precision(BigFloat; base = base), 8))")
            resid = maximum(abs.(f(z)))
            digits = floor(Int, -log(base, resid))
            digits = max(digits, min_digits) # not really needed, but keeps invariants consistent
        end

        # Final truncation: keep 16 guard bits
        final_bits = ceil(Int, (digits * log2(base) + 16))
        setprecision(BigFloat, final_bits)
        verbose && println("-"^(27))
        z .= BigFloat.(z)

        verbose && println(
            "Final accuracy ≈ $digits $basename\n",
            "Stored precision = $(precision(BigFloat; base = base)) $(basename)."
        )

        return z

    finally
        # Always restore global precision
        setprecision(BigFloat, old_bits)
        verbose && print("Original BigFloat global precision restored.")
    end
end
